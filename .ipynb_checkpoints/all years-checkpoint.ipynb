{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"aldi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to extract matches and players ' information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_matches_df(url):\n",
    "    try:\n",
    "        # Initialize Selenium\n",
    "        chrome_service = ChromeService(f\"C:/Users/{user}/Downloads/chromedriver.exe\")\n",
    "        chrome_service.start()\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "        # Navigate to the webpage\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the page to be loaded\n",
    "        loaded = False\n",
    "        while not loaded:\n",
    "            try:\n",
    "                main_element = driver.find_element(By.CLASS_NAME, \"main\")\n",
    "                loaded = True\n",
    "                print(\"Loaded!\")\n",
    "            except:\n",
    "                time.sleep(1)\n",
    "                print(\"waiting...\")\n",
    "        # ---------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Find the div element with class \"main\"\n",
    "        main_element = driver.find_element(By.CLASS_NAME, \"main\")\n",
    "\n",
    "        # Include the component_title_text in the stage variable\n",
    "        component_title_element = main_element.find_element(By.CLASS_NAME, \"component-title\")\n",
    "        stage = component_title_element.text.strip()\n",
    "\n",
    "        # ---------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Now, let's find the div element with class \"tie\" within the main element\n",
    "        tie_element = main_element.find_element(By.CLASS_NAME, \"details\")\n",
    "\n",
    "        # Find all sub div elements within the \"tie\" element\n",
    "        sub_div_elements = tie_element.find_elements(By.TAG_NAME, \"div\")\n",
    "\n",
    "        # Initialize variables to store data\n",
    "        column_data = {}\n",
    "\n",
    "        for sub_div_element in sub_div_elements:\n",
    "            sub_div_text = sub_div_element.text.strip()\n",
    "            if \":\" in sub_div_text:\n",
    "                column_name, column_value = sub_div_text.split(\":\", 1)\n",
    "                column_data[column_name] = [column_value]\n",
    "\n",
    "        # Create a DataFrame from the collected data\n",
    "        df = pd.DataFrame(column_data)\n",
    "\n",
    "        # Add the \"Stage\" column with the component_title_text\n",
    "        df[\"Stage\"] = stage\n",
    "\n",
    "        # ---------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Find the div element with class \"rubber-header\"\n",
    "        rubber_header_elements = main_element.find_elements(By.CLASS_NAME, \"rubber-header\")\n",
    "        match_num = []\n",
    "        match_status = []\n",
    "\n",
    "        for rubber_header_element in rubber_header_elements:\n",
    "\n",
    "            # Extract \"match\" and \"match status\" from the span elements\n",
    "            spans = rubber_header_element.find_elements(By.TAG_NAME, \"span\")\n",
    "\n",
    "            if len(spans) >= 2:\n",
    "                match_num.append(spans[0].text.strip())\n",
    "                match_status.append(spans[1].text.strip())\n",
    "            #       match = span_element.text.strip()\n",
    "\n",
    "        # ---------------------------------------------------------------------------------------------\n",
    "        # Now, let's find the div element with class \"rubber-body\" within the main element\n",
    "        rubber_body_elements = main_element.find_elements(By.CLASS_NAME, \"rubber-body\")\n",
    "        tables_data = []\n",
    "\n",
    "        match_idx = -1\n",
    "        for rubber_body_element in rubber_body_elements:\n",
    "            match_idx += 1\n",
    "\n",
    "            # Find all tables with class \"dc\" within the rubber-body\n",
    "            table_elements = rubber_body_element.find_elements(By.CLASS_NAME, \"dc\")\n",
    "\n",
    "            for table_element in table_elements:\n",
    "                # Initialize data for each table\n",
    "                table_data = {\n",
    "                    \"Player\": [],\n",
    "                    \"Set 1\": [],\n",
    "                    \"Set 2\": [],\n",
    "                    \"Set 3\": [],\n",
    "                    \"Tie-Break 1\": [],\n",
    "                    \"Tie-Break 2\": [],\n",
    "                    \"Tie-Break 3\": []\n",
    "                }\n",
    "\n",
    "                # Find the table body\n",
    "                tbody_element = table_element.find_element(By.TAG_NAME, \"tbody\")\n",
    "\n",
    "                # Find all rows (tr elements) within the tbody\n",
    "                rows = tbody_element.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "                for row in rows:\n",
    "                    # Find all td elements within the row\n",
    "                    td_elements = row.find_elements(By.TAG_NAME, \"td\")\n",
    "\n",
    "                    # Extract and store the information starting from td_elements[1]\n",
    "                    player = td_elements[1].text.strip()\n",
    "\n",
    "                    # Skip set and tie-break infos if match hasn't been played\n",
    "                    if match_status[match_idx] == \"NOT PLAYED\":\n",
    "                        print(f\"Skipping match {match_idx + 1}\")\n",
    "                        continue\n",
    "\n",
    "                    # Extract results from td class \"results\"\n",
    "                    results = td_elements[2]\n",
    "                    set_scores = results.find_elements(By.TAG_NAME, \"span\")\n",
    "\n",
    "                    set_results = []\n",
    "                    tie_breaks = []\n",
    "\n",
    "                    for set_score in set_scores:\n",
    "                        set_result = set_score.text.strip()\n",
    "                        tie_break = \"\"\n",
    "\n",
    "                        # Use regular expressions to extract the first number in set_result\n",
    "                        match = re.search(r'\\d+', set_result)\n",
    "                        if match:\n",
    "                            set_result = match.group()\n",
    "                        else:\n",
    "                            set_result = \"\"\n",
    "\n",
    "                        if set_score.find_elements(By.TAG_NAME, \"sup\"):\n",
    "                            tie_break = set_score.find_element(By.TAG_NAME, \"sup\").text.strip()\n",
    "                            # Use regular expressions to extract the first number in tie_break\n",
    "                            match = re.search(r'\\d+', tie_break)\n",
    "                            if match:\n",
    "                                tie_break = match.group()\n",
    "                            else:\n",
    "                                tie_break = \"\"\n",
    "\n",
    "                        set_results.append(set_result)\n",
    "                        tie_breaks.append(tie_break)\n",
    "\n",
    "                    # Ensure there are at most 3 sets\n",
    "                    set_results = set_results[:3]\n",
    "                    tie_breaks = tie_breaks[:3]\n",
    "\n",
    "                    # Assign the extracted values to the dictionary\n",
    "                    table_data[\"Player\"].append(player)\n",
    "                    table_data[\"Set 1\"].append(set_results[0])\n",
    "                    table_data[\"Set 2\"].append(set_results[1])\n",
    "                    table_data[\"Set 3\"].append(set_results[2])\n",
    "\n",
    "                    # Keep only the first element in the list for tie-breaks\n",
    "                    for i, tie_break in enumerate(tie_breaks):\n",
    "                        if i == 0 and tie_break:\n",
    "                            table_data[\"Tie-Break 1\"].append(tie_break)\n",
    "                        else:\n",
    "                            table_data[f\"Tie-Break {i + 1}\"].append(None)\n",
    "\n",
    "                # Append the table data to the list\n",
    "                tables_data.append(table_data)\n",
    "                print(table_data)\n",
    "\n",
    "        # Close the Selenium WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "        # Create a DataFrame from the collected data\n",
    "        tables_df = pd.DataFrame(tables_data)\n",
    "\n",
    "        # Combine the information from both DataFrames\n",
    "        matches_df = pd.concat([df] * len(tables_df), ignore_index=True)\n",
    "        matches_df = pd.concat([matches_df, tables_df], axis=1)\n",
    "\n",
    "        # Add match and match status columns\n",
    "        matches_df[\"match status\"] = \"\"\n",
    "        matches_df[\"match\"] = \"\"\n",
    "        for i in range(len(match_status)):\n",
    "            matches_df.loc[i * 2:(i * 2) + 1, \"match status\"] = match_status[i]\n",
    "            matches_df.loc[i * 2:(i * 2) + 1, \"match\"] = match_num[i]\n",
    "\n",
    "        # Display the combined DataFrame\n",
    "        print(\"Combined DataFrame:\")\n",
    "        print(matches_df)\n",
    "        return matches_df\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", str(e))\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_players_df(url):\n",
    "    try:\n",
    "        # Initialize Selenium\n",
    "        chrome_service = ChromeService(\"C:/Users/{user}/Downloads/chromedriver.exe\")\n",
    "        chrome_service.start()\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "        # Navigate to the webpage\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the page to load\n",
    "        loaded = False\n",
    "        while not loaded:\n",
    "            try:\n",
    "                main_element = driver.find_element(By.CLASS_NAME, \"main\")\n",
    "                loaded = True\n",
    "                print(\"Loaded!\")\n",
    "            except:\n",
    "                time.sleep(1)\n",
    "                print(\"waiting...\")\n",
    "\n",
    "        # Wait for the page to load\n",
    "        driver.implicitly_wait(10)  # You can adjust the waiting time as needed\n",
    "\n",
    "        # Find all div elements with class \"team-nominations-col\"\n",
    "        team_nominations_col_elements = driver.find_elements(By.CLASS_NAME, \"team-nominations-col\")\n",
    "\n",
    "        # Initialize a list to store the paired data\n",
    "        paired_data = []\n",
    "\n",
    "        # Initialize a list to store the column names\n",
    "        column_names = set()\n",
    "\n",
    "        # Loop through each \"team-nominations-col\" element\n",
    "        for team_nominations_col_element in team_nominations_col_elements:\n",
    "            # Extract the team name\n",
    "            team_name_element = team_nominations_col_element.find_element(By.CLASS_NAME, \"team-name\")\n",
    "            team_name = team_name_element.text.strip()\n",
    "\n",
    "            # Find \"players-info\" elements and extract text from \"ng-binding\" elements\n",
    "            players_info_elements = team_nominations_col_element.find_elements(By.CLASS_NAME, \"players-info\")\n",
    "\n",
    "            for players_info_element in players_info_elements:\n",
    "                ng_binding_elements = players_info_element.find_elements(By.CLASS_NAME, \"ng-binding\")\n",
    "\n",
    "                # Create a dictionary for the row\n",
    "                row_data = {\"Team Name\": team_name}\n",
    "\n",
    "                for i, ng_binding_element in enumerate(ng_binding_elements, start=1):\n",
    "                    row_data[f\"Info {i}\"] = ng_binding_element.text.strip()\n",
    "                    column_names.add(f\"Info {i}\")\n",
    "\n",
    "                paired_data.append(row_data)\n",
    "\n",
    "        # Create a Pandas DataFrame from the paired data\n",
    "        players_df = pd.DataFrame(paired_data)\n",
    "\n",
    "        # Reorder columns to match the column names\n",
    "        players_df = players_df[[\"Team Name\"] + sorted(column_names)]\n",
    "\n",
    "        # Now you have a DataFrame with team names and player information in separate columns\n",
    "        print(players_df)\n",
    "\n",
    "        return players_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", str(e))\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract links for all matches in a year and save them in lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  \n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\selenium\\webdriver\\common\\service.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m                                             \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                                             creationflags=self.creationflags)\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    774\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    776\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1179\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1da49cae33b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Initialize Selenium WebDriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C:/Users/{user}/Downloads/chromedriver.exe\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# URL of the webpage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://www.daviscup.com/en/draws-results/historic-format/world-group.aspx\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001b[0m\n\u001b[0;32m     71\u001b[0m                                         \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                                         \u001b[0mservice_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesired_capabilities\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                                         service_log_path, service, keep_alive)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mservice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\selenium\\webdriver\\common\\service.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m                 raise WebDriverException(\n\u001b[0;32m     82\u001b[0m                     \"'%s' executable needs to be in PATH. %s\" % (\n\u001b[1;32m---> 83\u001b[1;33m                         os.path.basename(self.path), self.start_error_message)\n\u001b[0m\u001b[0;32m     84\u001b[0m                 )\n\u001b[0;32m     85\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEACCES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Selenium WebDriver\n",
    "driver = webdriver.Chrome(executable_path=\"C:/Users/{user}/Downloads/chromedriver.exe\")\n",
    "\n",
    "# URL of the webpage\n",
    "url = \"https://www.daviscup.com/en/draws-results/historic-format/world-group.aspx\"\n",
    "\n",
    "# Navigate to the webpage\n",
    "driver.get(url)\n",
    "\n",
    "try:\n",
    "    # Wait for the page to load\n",
    "    driver.implicitly_wait(10)  # You can adjust the waiting time as needed\n",
    "\n",
    "    # Find all links with class \"tie-link\" within the tables\n",
    "    tie_links = driver.find_elements(By.CSS_SELECTOR, \"table.tie.ng-scope a.tie-link\")\n",
    "\n",
    "    # Initialize a list to store the extracted links\n",
    "    links = []\n",
    "\n",
    "    # Extract the links\n",
    "    for link in tie_links:\n",
    "        href = link.get_attribute(\"href\")\n",
    "        links.append(href)\n",
    "\n",
    "    # Create an empty list to store the results\n",
    "    match_results = []\n",
    "    player_results = []\n",
    "\n",
    "    # Iterate through the links and apply the functions\n",
    "    for link in links:\n",
    "        matches_df = extract_matches_df(link)\n",
    "        players_df = extract_players_df(link)\n",
    "        \n",
    "        if matches_df is not None:\n",
    "            match_results.append(matches_df)\n",
    "        if players_df is not None:\n",
    "            player_results.append(players_df)\n",
    "\n",
    "    # Close the Selenium WebDriver\n",
    "    driver.quit()\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", str(e))\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def to_df(links):\n",
    "    # Initialize ChromeOptions with headless mode\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "    # Initialize Selenium WebDriver with the provided executable path and headless option\n",
    "    driver = webdriver.Chrome(executable_path=\"C:/Users/{user}/Downloads/chromedriver.exe\", options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        # Create empty lists to store the results\n",
    "        match_results = []\n",
    "        player_results = []\n",
    "\n",
    "        for link in links:\n",
    "            # Apply the functions to extract match and player data\n",
    "            matches_df = extract_matches_df(link)\n",
    "            players_df = extract_players_df(link)\n",
    "\n",
    "            if matches_df is not None:\n",
    "                match_results.append(matches_df)\n",
    "            if players_df is not None:\n",
    "                player_results.append(players_df)\n",
    "\n",
    "        # Close the Selenium WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "        # Create DataFrames from the lists\n",
    "        matches_df = pd.concat(match_results, ignore_index=True)\n",
    "        players_df = pd.concat(player_results, ignore_index=True)\n",
    "\n",
    "        return matches_df, players_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", str(e))\n",
    "        driver.quit()\n",
    "\n",
    "    return None, None  # Return None if there was an error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function to scrape data for a single year and save the data in a dataframe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example:\n",
    "# URL of the webpage\n",
    "url = \"https://www.daviscup.com/en/draws-results/historic-format/world-group.aspx\"\n",
    "\n",
    "# Navigate to the webpage\n",
    "driver = webdriver.Chrome(executable_path=\"C:/Users/{user}/Downloads/chromedriver.exe\")\n",
    "driver.get(url)\n",
    "\n",
    "try:\n",
    "    # Wait for the page to load\n",
    "    driver.implicitly_wait(10)  # You can adjust the waiting time as needed\n",
    "\n",
    "    # Find all links with class \"tie-link\" within the tables\n",
    "    tie_links = driver.find_elements(By.CSS_SELECTOR, \"table.tie.ng-scope a.tie-link\")\n",
    "\n",
    "    # Initialize a list to store the extracted links\n",
    "    links = []\n",
    "\n",
    "    # Extract the links\n",
    "    for link in tie_links:\n",
    "        href = link.get_attribute(\"href\")\n",
    "        links.append(href)\n",
    "\n",
    "    # Call the function to scrape and transform the data\n",
    "    matches_df, players_df = to_df(links)\n",
    "\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df.iloc[90:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df.iloc[90:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows = players_df.duplicated()\n",
    "duplicate_rows_df = players_df[duplicate_rows]\n",
    "duplicate_rows_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean players and matches dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_players_df(players_df):\n",
    "    # Remove rows where Info 1 is equal to \"captain\"\n",
    "    players_df = players_df[players_df[\"Info 1\"] != \"Captain\"]\n",
    "    \n",
    "    # Rename the columns\n",
    "    players_df = players_df.rename(columns={\"Info 1\": \"Player\", \"Info 2\": \"DOB\", \"Info 3\": \"Single Ranking\", \"Info 4\": \"Doubles Ranking\"})\n",
    "    \n",
    "    # Remove text before \":\" in the specified columns\n",
    "    players_df[\"DOB\"] = players_df[\"DOB\"].str.split(\":\", expand=True)[1].str.strip()\n",
    "    players_df[\"Single Ranking\"] = players_df[\"Single Ranking\"].str.split(\":\", expand=True)[1].str.strip()\n",
    "    players_df[\"Doubles Ranking\"] = players_df[\"Doubles Ranking\"].str.split(\":\", expand=True)[1].str.strip()\n",
    "    \n",
    "    # Keep the first letter in each word in uppercase for the \"Player\" column in players_df\n",
    "    players_df['Player'] = players_df['Player'].str.title()\n",
    "    \n",
    "    return players_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example:\n",
    "# Call the clean_df_players function with your players_df DataFrame\n",
    "cleaned_players_df = clean_players_df(players_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_players_df.iloc[130:145]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_matches_df(matches_df):\n",
    "    # Convert \"Player\" and set columns to string\n",
    "    columns_to_convert = [\"Player\", \"Set 1\", \"Set 2\", \"Set 3\", \"Tie-Break 1\", \"Tie-Break 2\", \"Tie-Break 3\"]\n",
    "    matches_df[columns_to_convert] = matches_df[columns_to_convert].astype(str)\n",
    "\n",
    "    # Define a function to apply regular expression replacements\n",
    "    def apply_regex_replacements(df, columns):\n",
    "        for col in columns:\n",
    "            df[col] = df[col].str.replace(r'[\\[\\]\\']+| and ', '', regex=True)\n",
    "\n",
    "    # Apply the function to the specified columns\n",
    "    columns_to_clean = [\"Player\", \"Set 1\", \"Set 2\", \"Set 3\", \"Tie-Break 1\", \"Tie-Break 2\", \"Tie-Break 3\"]\n",
    "    apply_regex_replacements(matches_df, columns_to_clean)\n",
    "\n",
    "    # Apply the str.extract method with the specified regular expression\n",
    "    split_players = matches_df['Player'].str.extract(r'^(.*?)\\\\n(.*)$')\n",
    "    \n",
    "    # Create 'Player 1' and 'Player 2' columns\n",
    "    matches_df['Player 1'] = split_players[0].fillna(matches_df['Player'])\n",
    "    matches_df['Player 2'] = split_players[1].fillna('')\n",
    "    \n",
    "    # Drop the original 'Player' column\n",
    "    matches_df.drop('Player', axis=1, inplace=True)\n",
    "    \n",
    "    # Keep the first letter in each word in uppercase for the \"Player 1\" and \"Player 2\" columns\n",
    "    matches_df[\"Player 1\"] = matches_df[\"Player 1\"].str.title()\n",
    "    matches_df[\"Player 2\"] = matches_df[\"Player 2\"].str.title()\n",
    "    \n",
    "    # Define a function to convert specific columns from string to numeric\n",
    "    def convert_columns_to_numeric(df, columns):\n",
    "        for col in columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Specify the columns to convert\n",
    "    columns_to_convert = [\"Set 1\", \"Set 2\", \"Set 3\", \"Tie-Break 1\", \"Tie-Break 2\", \"Tie-Break 3\"]\n",
    "\n",
    "    # Apply the function to convert the specified columns\n",
    "    convert_columns_to_numeric(matches_df, columns_to_convert)\n",
    "    \n",
    "    return matches_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example:\n",
    "# Call the clean_df_combined function with your combined_df DataFrame\n",
    "cleaned_matches_df = clean_matches_df(matches_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_matches_df.iloc[80:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge players and matches dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data_frames(df1, df2):\n",
    "    # First merge based on \"Player\" matching \"Player 1\"\n",
    "    merged_df = df1.merge(df2, left_on='Player 1', right_on='Player', how='left')\n",
    "\n",
    "    # Second merge based on \"Player\" matching \"Player 2\"\n",
    "    merged_df = merged_df.merge(df2, left_on='Player 2', right_on='Player', how='left')\n",
    "\n",
    "    # Rename columns if needed\n",
    "    merged_df.rename(columns={'Name_x': 'Player_1_Name', 'Country_x': 'Player_1_Country',\n",
    "                             'Name_y': 'Player_2_Name', 'Country_y': 'Player_2_Country'}, inplace=True)\n",
    "\n",
    "    # Drop the duplicated columns\n",
    "    merged_df.drop(['Player_x', 'Player_y'], axis=1, inplace=True)\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df = merge_data_frames(cleaned_matches_df, cleaned_players_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.iloc[260:290]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the Excel file path\n",
    "excel_file_path = 'merged_data.xlsx'\n",
    "\n",
    "# Export merged_df to Excel\n",
    "merged_df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f\"Data has been exported to {excel_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve all years links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "# Path to the ChromeDriver\n",
    "chrome_driver_path = \"C:/Users/{user}/Downloads/chromedriver.exe\"\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "driver.get(\"https://www.daviscup.com/en/draws-results/historic-format/world-group.aspx\")\n",
    "driver.maximize_window()\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# Click on Accept All Cookies button\n",
    "acceptCookie_Btn = wait.until(EC.element_to_be_clickable((By.ID, \"onetrust-accept-btn-handler\")))\n",
    "driver.execute_script(\"arguments[0].click();\", acceptCookie_Btn)\n",
    "\n",
    "# Click on the dropdown arrow\n",
    "wait.until(EC.element_to_be_clickable((By.XPATH, \"//div[@class='selected']//div[@class='arrow']\"))).click()\n",
    "# Click on dropdown items from 2015 to 2018\n",
    "for year in range(2015, 2019):\n",
    "    year_xpath = f\"//a[text()='{year}']\"\n",
    "    year_element = wait.until(EC.element_to_be_clickable((By.XPATH, year_xpath)))\n",
    "    year_element.click()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
