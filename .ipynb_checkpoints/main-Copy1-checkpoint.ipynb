{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"ALESSANDRO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import external functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve all years links till 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALESSANDRO\\AppData\\Local\\Temp\\ipykernel_34588\\1246974148.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//a[text()='2014']\n",
      "<selenium.webdriver.remote.webelement.WebElement (session=\"10606ea8a615d5c2bf5dc2834530a95a\", element=\"A0F47AF1A78AFC3F8C7B727F0BAB6AA7_element_95\")>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALESSANDRO\\AppData\\Local\\Temp\\ipykernel_34588\\2024397676.py:7: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=f\"C:/Users/{user}/Downloads/chromedriver.exe\", options=chrome_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match: https://www.daviscup.com/en/draws-results/tie.aspx?id=M-DC-2014-WG-M-CZE-NED-01\n",
      "Initializing Selenium...\n",
      "Navigating to the webpage...\n",
      "Waiting for the page to load...\n",
      "matches df downloaded\n",
      "players df downloaded\n",
      "match: https://www.daviscup.com/en/draws-results/tie.aspx?id=M-DC-2014-WG-M-CAN-JPN-01\n",
      "Initializing Selenium...\n",
      "Navigating to the webpage...\n",
      "Waiting for the page to load...\n",
      "matches df downloaded\n",
      "players df downloaded\n",
      "match: https://www.daviscup.com/en/draws-results/tie.aspx?id=M-DC-2014-WG-M-ESP-GER-01\n",
      "Initializing Selenium...\n",
      "Navigating to the webpage...\n",
      "Waiting for the page to load...\n",
      "Skipping match 4\n",
      "Skipping match 4\n",
      "matches df downloaded\n",
      "players df downloaded\n",
      "match: https://www.daviscup.com/en/draws-results/tie.aspx?id=M-DC-2014-WG-M-FRA-AUS-01\n",
      "Initializing Selenium...\n",
      "Navigating to the webpage...\n",
      "Waiting for the page to load...\n",
      "matches df downloaded\n",
      "players df downloaded\n",
      "match: https://www.daviscup.com/en/draws-results/tie.aspx?id=M-DC-2014-WG-M-GBR-USA-01\n",
      "Initializing Selenium...\n",
      "Navigating to the webpage...\n",
      "Waiting for the page to load...\n",
      "Skipping match 5\n",
      "Skipping match 5\n",
      "matches df downloaded\n",
      "players df downloaded\n",
      "match: https://www.daviscup.com/en/draws-results/tie.aspx?id=M-DC-2014-WG-M-ITA-ARG-01\n",
      "Initializing Selenium...\n",
      "Navigating to the webpage...\n",
      "Waiting for the page to load...\n",
      "Skipping match 5\n",
      "Skipping match 5\n",
      "matches df downloaded\n",
      "players df downloaded\n",
      "match: https://www.daviscup.com/en/draws-results/tie.aspx?id=M-DC-2014-WG-M-BEL-KAZ-01\n",
      "Initializing Selenium...\n",
      "Navigating to the webpage...\n",
      "Waiting for the page to load...\n",
      "matches df downloaded\n",
      "players df downloaded\n",
      "match: https://www.daviscup.com/en/draws-results/tie.aspx?id=M-DC-2014-WG-M-SUI-SRB-01\n",
      "Initializing Selenium...\n",
      "Navigating to the webpage...\n",
      "Waiting for the page to load...\n",
      "matches df downloaded\n",
      "players df downloaded\n",
      "match: https://www.daviscup.com/en/draws-results/tie.aspx?id=M-DC-2014-WG-M-CZE-JPN-01\n",
      "Initializing Selenium...\n",
      "Navigating to the webpage...\n",
      "Waiting for the page to load...\n",
      "matches df downloaded\n",
      "players df downloaded\n",
      "match: https://www.daviscup.com/en/draws-results/tie.aspx?id=M-DC-2014-WG-M-GER-FRA-01\n",
      "Initializing Selenium...\n",
      "Navigating to the webpage...\n",
      "Waiting for the page to load...\n",
      "matches df downloaded\n",
      "players df downloaded\n",
      "match: https://www.daviscup.com/en/draws-results/tie.aspx?id=M-DC-2014-WG-M-GBR-ITA-01\n",
      "Initializing Selenium...\n",
      "Navigating to the webpage...\n",
      "Waiting for the page to load...\n",
      "matches df downloaded\n",
      "players df downloaded\n",
      "match: https://www.daviscup.com/en/draws-results/tie.aspx?id=M-DC-2014-WG-M-KAZ-SUI-01\n",
      "Initializing Selenium...\n",
      "Navigating to the webpage...\n",
      "Waiting for the page to load...\n",
      "matches df downloaded\n",
      "players df downloaded\n",
      "match: https://www.daviscup.com/en/draws-results/tie.aspx?id=M-DC-2014-WG-M-CZE-FRA-01\n",
      "Initializing Selenium...\n",
      "Navigating to the webpage...\n",
      "Waiting for the page to load...\n",
      "[ERROR] Exception occurred: No objects to concatenate\n",
      "players df downloaded\n",
      "match: https://www.daviscup.com/en/draws-results/tie.aspx?id=M-DC-2014-WG-M-ITA-SUI-01\n",
      "Initializing Selenium...\n",
      "Navigating to the webpage...\n",
      "Waiting for the page to load...\n",
      "matches df downloaded\n",
      "players df downloaded\n",
      "match: https://www.daviscup.com/en/draws-results/tie.aspx?id=M-DC-2014-WG-M-FRA-SUI-01\n",
      "Initializing Selenium...\n",
      "Navigating to the webpage...\n",
      "Waiting for the page to load...\n",
      "Skipping match 5\n",
      "Skipping match 5\n",
      "matches df downloaded\n",
      "players df downloaded\n",
      "Total number of rows in matches_df: 132\n",
      "Total number of rows in players_df: 149\n"
     ]
    }
   ],
   "source": [
    "# webpage to scrape\n",
    "url = \"https://www.daviscup.com/en/draws-results/historic-format/world-group.aspx\"\n",
    "\n",
    "# Path to the ChromeDriver\n",
    "chrome_driver_path = f\"C:/Users/{user}/Downloads/chromedriver.exe\"\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# Click on Accept All Cookies button\n",
    "acceptCookie_Btn = wait.until(EC.element_to_be_clickable((By.ID, \"onetrust-accept-btn-handler\")))\n",
    "driver.execute_script(\"arguments[0].click();\", acceptCookie_Btn)\n",
    "\n",
    "# Initialize an empty DataFrame to store all the data\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# Loop through selected years\n",
    "for year in range(2014,2013 , -1): \n",
    "    # Click on the dropdown arrow\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, \"//div[@class='selected']//div[@class='arrow']\"))).click()\n",
    "    time.sleep(4)  # Introduce a delay before clicking the element\n",
    "    year_xpath = f\"//a[text()='{year}']\"\n",
    "    print(year_xpath)\n",
    "    \n",
    "    try:\n",
    "        # Locate the element for the specific year and click it\n",
    "        year_element = wait.until(EC.presence_of_element_located((By.XPATH, year_xpath)))\n",
    "        print(year_element)        \n",
    "        # Click on the element\n",
    "        year_element.click()\n",
    "        \n",
    "        # Wait for the page to load\n",
    "        driver.implicitly_wait(10)  # You can adjust the waiting time as needed\n",
    "        time.sleep(10)\n",
    "\n",
    "        # Find all links with class \"tie-link\" within the tables\n",
    "        tie_links = driver.find_elements(By.CSS_SELECTOR, \"table.tie.ng-scope a.tie-link\")\n",
    "\n",
    "        # Initialize a list to store the extracted links\n",
    "        links = []\n",
    "\n",
    "        # Extract the links\n",
    "        for link in tie_links:\n",
    "            href = link.get_attribute(\"href\")\n",
    "            links.append(href)\n",
    "\n",
    "        # Call the function to scrape and transform the data\n",
    "        matches_df, players_df = to_df(links)\n",
    "        # Cleaning DataFrames\n",
    "        cleaned_matches_df = clean_matches_df(matches_df)\n",
    "        cleaned_players_df = clean_players_df(players_df)\n",
    "\n",
    "        # Merging DataFrames\n",
    "        merged_df = merge_data_frames(cleaned_matches_df, cleaned_players_df)\n",
    "        # Add a column with the respective year information\n",
    "        merged_df['Year'] = year\n",
    "\n",
    "        # Append data to the final DataFrame\n",
    "        final_df = pd.concat([final_df, merged_df], ignore_index=True)\n",
    "        # Save the current year's data to a separate Excel file\n",
    "        year_file_name = f\"davis_{year}.xlsx\"\n",
    "        final_df.to_excel(year_file_name, index=False)\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(f\"TimeoutException occurred while locating element for year {year}. Skipping...\")\n",
    "        continue  # Skip to the next iteration if element not found within the timeout\n",
    "        \n",
    "# Save the final DataFrame to an Excel file\n",
    "# final_df.to_excel(\"old_system.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a year I have 15 matches (number of link), each match has a max number of 5 matches and on avg 4 matches. The number of single matches should be therefore between 60 and 70. We have two observations (one for each player or team) for each match for a total of 120/140 rows (max 75*2 = 150).\n",
    "\n",
    "We have 5 players in each team, two team in each match, and 15 matches for a total of (5 * 2 * 15) 150 players/teams.\n",
    "\n",
    "players of teams advancing to the next stage appear more than ones with the same information. it would be efficient to not repeat the data collection for those observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve all years links from 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALESSANDRO\\AppData\\Local\\Temp\\ipykernel_34588\\3084927575.py:4: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Wait for the page to load\u001b[39;00m\n\u001b[0;32m     20\u001b[0m driver\u001b[38;5;241m.\u001b[39mimplicitly_wait(\u001b[38;5;241m10\u001b[39m)  \u001b[38;5;66;03m# You can adjust the waiting time as needed\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Find all links with class \"tie-link\" within the tables\u001b[39;00m\n\u001b[0;32m     24\u001b[0m tie_links \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmatchable.tie.ng-scope a.tie-link\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# webpage to scrape\n",
    "url = (\"https://www.daviscup.com/en/draws-results/finals/2019.aspx\")\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "\n",
    "# Initialize an empty DataFrame to store all the data\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# Initialize dictionaries to store DataFrames\n",
    "matches_dataframes = {}\n",
    "players_dataframes = {}\n",
    "cleaned_matches_dataframes = {}\n",
    "cleaned_players_dataframes = {}\n",
    "merged_dataframes = {}\n",
    "\n",
    "# Loop through selected years (2019 to 2023)\n",
    "for year in range(2021, 2022):  # Change the range accordingly\n",
    "    current_url = f\"https://www.daviscup.com/en/draws-results/finals/{year}.aspx\"\n",
    "    \n",
    "    try:\n",
    "        driver.get(current_url)\n",
    "        # Wait for the page to load\n",
    "        driver.implicitly_wait(10)  # You can adjust the waiting time as needed\n",
    "        time.sleep(10)\n",
    "\n",
    "        # Find all links with class \"tie-link\" within the tables\n",
    "        tie_links = driver.find_elements(By.CSS_SELECTOR, \"tmatchable.tie.ng-scope a.tie-link\")\n",
    "        \n",
    "        # Initialize a list to store the extracted links\n",
    "        links = []\n",
    "\n",
    "        # Extract the links\n",
    "        for link in tie_links:\n",
    "            href = link.get_attribute(\"href\")\n",
    "            links.append(href)\n",
    "\n",
    "        # Call the function to scrape and transform the data\n",
    "        matches_df, players_df = to_df(links)\n",
    "        # Cleaning DataFrames\n",
    "        cleaned_matches_df = clean_matches_df(matches_df)\n",
    "        cleaned_players_df = clean_players_df(players_df)\n",
    "\n",
    "        # Merging DataFrames\n",
    "        merged_df = merge_data_frames(cleaned_matches_df, cleaned_players_df)\n",
    "        # Add a column with the respective year information\n",
    "        merged_df['Year'] = year\n",
    "\n",
    "        # Append data to the final DataFrame\n",
    "        final_df = pd.concat([final_df, merged_df], ignore_index=True)\n",
    "        # Save the current year's data to a separate Excel file\n",
    "        year_file_name = f\"davis_{year}.xlsx\"\n",
    "        final_df.to_excel(year_file_name, index=False)\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(f\"TimeoutException occurred while processing year {year}. Skipping...\")\n",
    "        continue  # Skip to the next iteration if page not loaded within the timeout\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for year {year}: {str(e)}\")\n",
    "        continue  # Continue to the next iteration if an error occurs\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a year I have 7 matches (number of link), each match has a max number of 3 matches. The number of single matches should be 21. We have two observations (one for each player or team) for each match for a total of 42 (21*2) rows.\n",
    "\n",
    "We have 5 players in each team, two team in each match, and 7 matches for a total of (5 * 2 * 7) 70 players/teams.\n",
    "We have on avg 5 player per team and 8 teams competing from the quarter finals, for a total of 40 (8*5) players.\n",
    "\n",
    "players of teams advancing to the next stage appear more than ones with the same information. it would be efficient to not repeat the data collection for those observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "total_unique_info1 = players_df['Info 1'].nunique()\n",
    "print(total_unique_info1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
