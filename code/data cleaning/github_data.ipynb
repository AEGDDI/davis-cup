{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from getpass import getuser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = getuser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_path = f\"C:/Users/{user}/Documents/GitHub/davis-cup/data/single matches/\"\n",
    "website_path = f\"C:/Users/{user}/Documents/GitHub/davis-cup/data/website_df.xlsx\"\n",
    "website_df = pd.read_excel(website_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494, 19)\n",
      "(387, 19)\n",
      "(107, 19)\n"
     ]
    }
   ],
   "source": [
    "# Create the single_matches_web dataframe by selecting rows where p2t1 and p2t2 are empty\n",
    "single_matches_web_df = website_df[website_df['p2t1'].isna() & website_df['p2t2'].isna()]\n",
    "double_matches_web_df = website_df[website_df['p2t1'].notna() & website_df['p2t2'].notna()]\n",
    "print(website_df.shape)\n",
    "print(single_matches_web_df.shape)\n",
    "print(double_matches_web_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single_matches_web_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daniel Brands (Germany) vs Roberto Bautista Agut (Spain) is recorded as match number 4 in website_df since in the match before Feliciano Lopez (Spain) walked over Philipp Kohlschreiber (Germany). In website_df, we therefore consider it as a match not played whereas in github_df the number of match is preserved. We therefore change match number in website_df to make it consistent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the number of match  \n",
    "single_matches_web_df.loc[\n",
    "    (single_matches_web_df['year'] == 2014) &\n",
    "    (single_matches_web_df['team1'] == 'germany') &\n",
    "    (single_matches_web_df['team2'] == 'spain') &\n",
    "    (single_matches_web_df['match'] == 4), 'match'] = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# github data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of years to include\n",
    "years = range(2013, 2024)\n",
    "dfs = []\n",
    "\n",
    "for year in years:\n",
    "    atp_matches_path = f\"{github_path}atp_matches_{year}.csv\"\n",
    "    df = pd.read_csv(atp_matches_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenating all the DataFrames into one\n",
    "atp_matches_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Extract the year from the 'tourney_id' by splitting the string at the first hyphen and taking the first part\n",
    "atp_matches_df['year'] = atp_matches_df['tourney_id'].str.split('-').str[0]\n",
    "\n",
    "# Convert the 'year' column to an integer\n",
    "atp_matches_df['year'] = atp_matches_df['year'].astype(int)\n",
    "\n",
    "# Replacing \"Frances Tiafoe\" with \"Franklin Tiafoe\" in both the 'winner_name' and 'loser_name' columns\n",
    "atp_matches_df['winner_name'] = atp_matches_df['winner_name'].replace('Frances Tiafoe', 'Franklin Tiafoe')\n",
    "atp_matches_df['loser_name'] = atp_matches_df['loser_name'].replace('Frances Tiafoe', 'Franklin Tiafoe')\n",
    "\n",
    "# Replacing \"Andreas Haider Maurer\" with \"Andreas Haider-Maurer\" in both the 'winner_name' and 'loser_name' columns\n",
    "atp_matches_df['winner_name'] = atp_matches_df['winner_name'].replace('Andreas Haider Maurer', 'Andreas Haider-Maurer')\n",
    "atp_matches_df['loser_name'] = atp_matches_df['loser_name'].replace('Andreas Haider Maurer', 'Andreas Haider-Maurer')\n",
    "\n",
    "# Replacing \"Guillermo Garcia Lopez\" with \"Guillermo Garcia-Lopez\" in both the 'winner_name' and 'loser_name' columns\n",
    "atp_matches_df['winner_name'] = atp_matches_df['winner_name'].replace('Guillermo Garcia Lopez', 'Guillermo Garcia-Lopez')\n",
    "atp_matches_df['loser_name'] = atp_matches_df['loser_name'].replace('Guillermo Garcia Lopez', 'Guillermo Garcia-Lopez')\n",
    "\n",
    "# Save the combined data to a single Excel file\n",
    "final_output_path = f\"C:/Users/{user}/Documents/GitHub/davis-cup/data/single matches/atp_matches_df.xlsx\"\n",
    "atp_matches_df.to_excel(final_output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# github repo matched observations with website df players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store all ATP matches where Davis Cup players took part\n",
    "combined_matches_list = []\n",
    "\n",
    "# Iterate through each year to filter the matches\n",
    "for year in range(2013, 2024):\n",
    "    # Filter Davis Cup data for the current year\n",
    "    davis_single_year_df = single_matches_web_df[single_matches_web_df['year'] == year]\n",
    "    \n",
    "    # Create a set of tuples representing pairs of players for the current year\n",
    "    davis_pairs = set(zip(davis_single_year_df['p1t1'], davis_single_year_df['p1t2']))\n",
    "    \n",
    "    # Filter ATP matches data to match Davis Cup pairs for the current year\n",
    "    matched_atp_matches_df = atp_matches_df[\n",
    "        (atp_matches_df['year'] == year) &\n",
    "        atp_matches_df.apply(lambda row: (row['winner_name'], row['loser_name']) in davis_pairs or\n",
    "                                           (row['loser_name'], row['winner_name']) in davis_pairs, axis=1)\n",
    "    ]\n",
    "    \n",
    "    # Append the filtered data to the list\n",
    "    combined_matches_list.append(matched_atp_matches_df)\n",
    "\n",
    "# Concatenate all the DataFrames in the list into one combined DataFrame\n",
    "combined_matches_df = pd.concat(combined_matches_list, ignore_index=True)\n",
    "\n",
    "# Save the combined data to a single Excel file\n",
    "final_output_path = f\"C:/Users/{user}/Documents/GitHub/davis-cup/data/single matches/davis_cup_players.xlsx\"\n",
    "combined_matches_df.to_excel(final_output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations for davis cup matches from github 387\n",
      "Number of observations for matches played by davis cup players outside davis cup: 131\n"
     ]
    }
   ],
   "source": [
    "# Count the number of observations where tourney_level is \"D\" - Davis Cup\n",
    "davis_single_github_count = combined_matches_df[combined_matches_df['tourney_level'] == 'D'].shape[0]\n",
    "\n",
    "# Count the number of observations where tourney_level is not \"D\"\n",
    "extra_matches_single_count = combined_matches_df[combined_matches_df['tourney_level'] != 'D'].shape[0]\n",
    "\n",
    "print(\"Number of observations for davis cup matches from github\", davis_single_github_count)\n",
    "print(\"Number of observations for matches played by davis cup players outside davis cup:\", extra_matches_single_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "130 is the number of games played in other atp matches by davis cup players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# github dataset single match players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 50)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new DataFrame with observations where tourney_level is \"D\"\n",
    "single_github_df = combined_matches_df[combined_matches_df['tourney_level'] == 'D']\n",
    "single_github_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have 387 observations for single davis matches for both single_github_df and single_matches_web_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# list from github dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2013, 1, 'Carlos Berlocq', 'Philipp Kohlschreiber'], [2013, 2, 'Florian Mayer', 'Juan Monaco'], [2013, 4, 'Juan Monaco', 'Tobias Kamke'], [2013, 5, 'Carlos Berlocq', 'Christopher Kas'], [2013, 1, 'David Goffin', 'Viktor Troicki']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating a list with year, match_num, winner_name, loser_name, where names are alphabetically ordered\n",
    "github_list = single_github_df.apply(\n",
    "    lambda row: [row['year'],row['match_num'], *sorted([row['winner_name'], row['loser_name']])], \n",
    "    axis=1\n",
    ").tolist()\n",
    "\n",
    "# Optionally, print the first few elements in the list to verify\n",
    "print(github_list[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# list from website df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2013, 1, 'Albert Ramos', 'Milos Raonic'], [2013, 2, 'Frank Dancevic', 'Marcel Granollers'], [2013, 4, 'Guillermo Garcia-Lopez', 'Milos Raonic'], [2013, 5, 'Albert Ramos', 'Frank Dancevic'], [2013, 1, 'Marin Cilic', 'Paolo Lorenzi']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Creating a list with Year, cleaned Match, P1T1, P1T2, where player names are alphabetically ordered\n",
    "website_list = single_matches_web_df.apply(\n",
    "    lambda row: [row['year'], row['match'], *sorted([row['p1t1'], row['p1t2']])],\n",
    "    axis=1\n",
    ").tolist()\n",
    "\n",
    "# Optionally, print the first few elements in the list to verify\n",
    "print(website_list[:5])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-matching elements in standardized_web_list: set()\n",
      "Non-matching elements in standardized_github_list: set()\n",
      "Number of unmatched elements in num_yes_github_no_web: 0\n",
      "Number of unmatched elements in num_no_github_yes_web: 0\n"
     ]
    }
   ],
   "source": [
    "# Standardizing formats in matches_list and davis_single_list\n",
    "# Assuming year and match number are integers, and player names are strings\n",
    "\n",
    "standardized_github_list = [\n",
    "    [int(year), int(match_num), str(winner_name), str(loser_name)]\n",
    "    for year, match_num, winner_name, loser_name in github_list\n",
    "]\n",
    "\n",
    "standardized_web_list = [\n",
    "    [int(year),int(match_num), str(player1), str(player2)]\n",
    "    for year, match_num, player1, player2 in website_list\n",
    "]\n",
    "\n",
    "# Convert to sets of tuples for comparison\n",
    "standardized_github_set = set(tuple(item) for item in standardized_github_list)\n",
    "standardized_web_set = set(tuple(item) for item in standardized_web_list)\n",
    "\n",
    "# Find non-matching elements in both sets\n",
    "yes_github_no_web = standardized_github_set - standardized_web_set\n",
    "no_github_yes_web = standardized_web_set - standardized_github_set\n",
    "\n",
    "print(\"Non-matching elements in standardized_web_list:\", yes_github_no_web)\n",
    "print(\"Non-matching elements in standardized_github_list:\", no_github_yes_web)\n",
    "\n",
    "# Count the number of non-matching tuples in standardized_github_list\n",
    "num_yes_github_no_web = len(yes_github_no_web)\n",
    "\n",
    "# Count the number of non-matching tuples in standardized_web_list\n",
    "num_no_github_yes_web = len(no_github_yes_web)\n",
    "\n",
    "print(\"Number of unmatched elements in num_yes_github_no_web:\", num_yes_github_no_web)\n",
    "print(\"Number of unmatched elements in num_no_github_yes_web:\", num_no_github_yes_web)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge two datasets single_github_df and single_matches_web_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALESSANDRO\\AppData\\Local\\Temp\\ipykernel_37380\\3080678659.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_github_df['year'] = single_github_df['year'].astype(int)\n",
      "C:\\Users\\ALESSANDRO\\AppData\\Local\\Temp\\ipykernel_37380\\3080678659.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_matches_web_df['year'] = single_matches_web_df['year'].astype(int)\n",
      "C:\\Users\\ALESSANDRO\\AppData\\Local\\Temp\\ipykernel_37380\\3080678659.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_github_df['winner_name'] = single_github_df['winner_name'].str.lower().str.strip()\n",
      "C:\\Users\\ALESSANDRO\\AppData\\Local\\Temp\\ipykernel_37380\\3080678659.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_github_df['loser_name'] = single_github_df['loser_name'].str.lower().str.strip()\n",
      "C:\\Users\\ALESSANDRO\\AppData\\Local\\Temp\\ipykernel_37380\\3080678659.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_matches_web_df['p1t1'] = single_matches_web_df['p1t1'].str.lower().str.strip()\n",
      "C:\\Users\\ALESSANDRO\\AppData\\Local\\Temp\\ipykernel_37380\\3080678659.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_matches_web_df['p1t2'] = single_matches_web_df['p1t2'].str.lower().str.strip()\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'year' is an integer in single_github_df\n",
    "single_github_df['year'] = single_github_df['year'].astype(int)\n",
    "\n",
    "# Ensure 'year' is an integer in single_matches_web_df\n",
    "single_matches_web_df['year'] = single_matches_web_df['year'].astype(int)\n",
    "\n",
    "# Standardize case and remove leading/trailing spaces in single_github_df\n",
    "single_github_df['winner_name'] = single_github_df['winner_name'].str.lower().str.strip()\n",
    "single_github_df['loser_name'] = single_github_df['loser_name'].str.lower().str.strip()\n",
    "\n",
    "# Standardize case and remove leading/trailing spaces in single_matches_web_df\n",
    "single_matches_web_df['p1t1'] = single_matches_web_df['p1t1'].str.lower().str.strip()\n",
    "single_matches_web_df['p1t2'] = single_matches_web_df['p1t2'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tourney_id             object\n",
      "tourney_name           object\n",
      "surface                object\n",
      "draw_size               int64\n",
      "tourney_level          object\n",
      "tourney_date            int64\n",
      "match_num               int64\n",
      "winner_id               int64\n",
      "winner_seed           float64\n",
      "winner_entry           object\n",
      "winner_name            object\n",
      "winner_hand            object\n",
      "winner_ht             float64\n",
      "winner_ioc             object\n",
      "winner_age            float64\n",
      "loser_id                int64\n",
      "loser_seed            float64\n",
      "loser_entry            object\n",
      "loser_name             object\n",
      "loser_hand             object\n",
      "loser_ht              float64\n",
      "loser_ioc              object\n",
      "loser_age             float64\n",
      "score                  object\n",
      "best_of                 int64\n",
      "round                  object\n",
      "minutes               float64\n",
      "w_ace                 float64\n",
      "w_df                  float64\n",
      "w_svpt                float64\n",
      "w_1stIn               float64\n",
      "w_1stWon              float64\n",
      "w_2ndWon              float64\n",
      "w_SvGms               float64\n",
      "w_bpSaved             float64\n",
      "w_bpFaced             float64\n",
      "l_ace                 float64\n",
      "l_df                  float64\n",
      "l_svpt                float64\n",
      "l_1stIn               float64\n",
      "l_1stWon              float64\n",
      "l_2ndWon              float64\n",
      "l_SvGms               float64\n",
      "l_bpSaved             float64\n",
      "l_bpFaced             float64\n",
      "winner_rank           float64\n",
      "winner_rank_points    float64\n",
      "loser_rank            float64\n",
      "loser_rank_points     float64\n",
      "year                    int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(single_github_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ball                 object\n",
      "stage                object\n",
      "match                 int64\n",
      "year                  int32\n",
      "p1t1                 object\n",
      "p2t1                 object\n",
      "p1t2                 object\n",
      "p2t2                 object\n",
      "team1                object\n",
      "team2                object\n",
      "date_start           object\n",
      "date_end             object\n",
      "venue_name           object\n",
      "city                 object\n",
      "country              object\n",
      "main_surface         object\n",
      "specific_surface     object\n",
      "indoor_outdoor       object\n",
      "court_pace_rating    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(single_matches_web_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unmatched rows in the final merged DataFrame: 0\n"
     ]
    }
   ],
   "source": [
    "# Direct match merge\n",
    "merged_df = pd.merge(\n",
    "    single_github_df, \n",
    "    single_matches_web_df, \n",
    "    how='left', \n",
    "    left_on=['year', 'winner_name', 'loser_name'], \n",
    "    right_on=['year', 'p1t1', 'p1t2'],\n",
    "    indicator=True  # Adds a column to indicate if the merge was successful\n",
    ")\n",
    "\n",
    "# Reverse match merge (loser_name vs. winner_name) on the resulting DataFrame\n",
    "merged_df_reverse = pd.merge(\n",
    "    merged_df, \n",
    "    single_matches_web_df, \n",
    "    how='left', \n",
    "    left_on=['year', 'loser_name', 'winner_name'], \n",
    "    right_on=['year', 'p1t1', 'p1t2'],\n",
    "    indicator='merge_reverse',  # Renames the indicator column for this merge\n",
    "    suffixes=('', '_reverse')  # To distinguish the columns from the second merge\n",
    ")\n",
    "\n",
    "# Drop duplicates if any\n",
    "merged_df_final = merged_df_reverse.drop_duplicates()\n",
    "\n",
    "# Remove all rows that have only empty cells\n",
    "merged_df_final = merged_df_final.dropna(how='all')\n",
    "\n",
    "# Check for unmatched rows after both merges\n",
    "unmatched_rows_df = merged_df_final[\n",
    "    (merged_df_final['_merge'] == 'left_only') & \n",
    "    (merged_df_final['merge_reverse'] == 'left_only')\n",
    "]\n",
    "\n",
    "# Count the number of unmatched rows\n",
    "num_unmatched = unmatched_rows_df.shape[0]\n",
    "\n",
    "print(f\"Number of unmatched rows in the final merged DataFrame: {num_unmatched}\")\n",
    "\n",
    "# If needed, you can inspect these unmatched rows\n",
    "if num_unmatched > 0:\n",
    "    print(\"Unmatched rows:\")\n",
    "    print(unmatched_rows_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 88)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported to C:/Users/ALESSANDRO/Documents/GitHub/davis-cup/data/davis_singles.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = f\"C:/Users/{user}/Documents/GitHub/davis-cup/data/davis_singles.xlsx\"\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "merged_df_final.to_excel(file_path, index=False)\n",
    "\n",
    "print(f\"DataFrame exported to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filtered_atp_matches.xlsx in single matches folder = final df for single matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# matches played by davis players outside davis cup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double matches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
