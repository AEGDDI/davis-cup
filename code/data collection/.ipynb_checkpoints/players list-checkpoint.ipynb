{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "user = \"aldi\"  # Replace with the actual username\n",
    "file_path = f\"C:/Users/{user}/Documents/GitHub/davis-cup/data/combined_davis.xlsx\"  \n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loop through the DataFrame and mark rows for deletion\n",
    "to_delete = []\n",
    "for i in range(len(df) - 1):\n",
    "    # Check for consecutive rows with \"Sam Groth\" as \"Player 1\" and \"John Peers\" as \"Player 2\"\n",
    "    if (df.iloc[i]['Player 1'] == \"Sam Groth\" and \n",
    "        df.iloc[i]['Player 2'] == \"John Peers\" and\n",
    "        df.iloc[i]['Player 1'] == df.iloc[i + 1]['Player 1'] and\n",
    "        df.iloc[i]['Player 2'] == df.iloc[i + 1]['Player 2']):\n",
    "        to_delete.append(i + 1)\n",
    "    \n",
    "    # Check for consecutive rows with \"Jordan Thompson\" as \"Player 1\"\n",
    "    elif (df.iloc[i]['Player 1'] == \"Jordan Thompson\" and \n",
    "          df.iloc[i]['Player 1'] == df.iloc[i + 1]['Player 1']):\n",
    "        to_delete.append(i + 1)\n",
    "\n",
    "    # Check for consecutive rows with \"Nick Kyrgios\" as \"Player 1\"\n",
    "    elif (df.iloc[i]['Player 1'] == \"Nick Kyrgios\" and \n",
    "          df.iloc[i]['Player 1'] == df.iloc[i + 1]['Player 1']):\n",
    "        to_delete.append(i + 1)\n",
    "        \n",
    "    # Check for consecutive rows with \"Sam Groth\" as \"Player 1\"\n",
    "    elif (df.iloc[i]['Player 1'] == \"Sam Groth\" and \n",
    "          df.iloc[i]['Player 1'] == df.iloc[i + 1]['Player 1']):\n",
    "        to_delete.append(i + 1)\n",
    "    # Check for consecutive rows with \"Sam Groth\" as \"Player 1\" and \"John Peers\" as \"Player 2\"\n",
    "    elif (df.iloc[i]['Player 1'] == \"John Peers\" and \n",
    "        df.iloc[i]['Player 2'] == \"Jordan Thompson\" and\n",
    "        df.iloc[i]['Player 1'] == df.iloc[i + 1]['Player 1'] and\n",
    "        df.iloc[i]['Player 2'] == df.iloc[i + 1]['Player 2']):\n",
    "        to_delete.append(i + 1)\n",
    "\n",
    "\n",
    "# Remove the marked rows\n",
    "df_cleaned = df.drop(df.index[to_delete])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (866, 28)\n",
      "df_cleaned shape: (846, 28)\n",
      "df_paired shape: (423, 10)\n"
     ]
    }
   ],
   "source": [
    "# Extract the relevant columns and rename them\n",
    "df_extracted = df_cleaned[['Stage', 'Player 1', 'Player 2', 'Year', 'Date', 'Venue', 'Court Pace Rating', 'Ball', 'match']].copy()\n",
    "df_extracted.rename(columns={'Player 1': 'P1T1', 'Player 2': 'P2T1'}, inplace=True)\n",
    "\n",
    "# Helper function to pair rows with the additional condition that \"Date\" should be equal\n",
    "def pair_rows(df):\n",
    "    paired_rows = []\n",
    "    for i in range(0, len(df), 2):\n",
    "        if i+1 < len(df):\n",
    "            row1 = df.iloc[i]\n",
    "            row2 = df.iloc[i+1]\n",
    "            if row1['match'] == row2['match'] and row1['Year'] == row2['Year'] and row1['Date'] == row2['Date']:\n",
    "                paired_row = [row1['match'], row1['Year'], row1['P1T1'], row1['P2T1'], row2['P1T1'], row2['P2T1'], row1['Date'], row1['Venue'], row1['Court Pace Rating'], row1['Ball']]\n",
    "                paired_rows.append(paired_row)\n",
    "    paired_df = pd.DataFrame(paired_rows, columns=['Match', 'Year', 'P1T1', 'P2T1', 'P1T2', 'P2T2', 'Date', 'Venue', 'Court Pace Rating', 'Ball'])\n",
    "    return paired_df\n",
    "\n",
    "# Pair the rows in the extracted dataframe\n",
    "df_paired = pair_rows(df_extracted)\n",
    "\n",
    "# Replace specific player names to match with data from atp matches\n",
    "df_paired.replace({\n",
    "    'P1T1': {\n",
    "        'Jan-Lennard Struff': 'Jan Lennard Struff',\n",
    "        'Juan Martin Del Potro': 'Juan Martin del Potro',\n",
    "        'Albert Ramos-Vinolas': 'Albert Ramos',\n",
    "        'Felix Auger-Aliassime': 'Felix Auger Aliassime',\n",
    "        'Pierre-Hugues Herbert': 'Pierre Hugues Herbert',\n",
    "        'Marc-Andrea Huesler': 'Marc Andrea Huesler',\n",
    "        'Roman Khassanov': 'Roman Hassanov'\n",
    "    },\n",
    "    'P2T1': {\n",
    "        'Jan-Lennard Struff': 'Jan Lennard Struff',\n",
    "        'Juan Martin Del Potro': 'Juan Martin del Potro',\n",
    "        'Albert Ramos-Vinolas': 'Albert Ramos',\n",
    "        'Felix Auger-Aliassime': 'Felix Auger Aliassime',\n",
    "        'Pierre-Hugues Herbert': 'Pierre Hugues Herbert',\n",
    "        'Marc-Andrea Huesler': 'Marc Andrea Huesler',\n",
    "        'Roman Khassanov': 'Roman Hassanov'\n",
    "\n",
    "    },\n",
    "    'P1T2': {\n",
    "        'Jan-Lennard Struff': 'Jan Lennard Struff',\n",
    "        'Juan Martin Del Potro': 'Juan Martin del Potro',\n",
    "        'Albert Ramos-Vinolas': 'Albert Ramos',\n",
    "        'Felix Auger-Aliassime': 'Felix Auger Aliassime',\n",
    "         'Pierre-Hugues Herbert': 'Pierre Hugues Herbert',\n",
    "        'Marc-Andrea Huesler': 'Marc Andrea Huesler',\n",
    "        'Roman Khassanov': 'Roman Hassanov'\n",
    "\n",
    "    },\n",
    "    'P2T2': {\n",
    "        'Jan-Lennard Struff': 'Jan Lennard Struff',\n",
    "        'Juan Martin Del Potro': 'Juan Martin del Potro',\n",
    "        'Albert Ramos-Vinolas': 'Albert Ramos',\n",
    "        'Felix Auger-Aliassime': 'Felix Auger Aliassime',\n",
    "         'Pierre-Hugues Herbert': 'Pierre Hugues Herbert',\n",
    "        'Marc-Andrea Huesler': 'Marc Andrea Huesler',\n",
    "        'Roman Khassanov': 'Roman Hassanov'\n",
    "\n",
    "    }\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# Print the shapes of the dataframes\n",
    "print(\"df shape:\", df.shape)\n",
    "print(\"df_cleaned shape:\", df_cleaned.shape)\n",
    "print(\"df_paired shape:\", df_paired.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All matches are in the correct range.\n"
     ]
    }
   ],
   "source": [
    "# Group by Date, Year, and Venue, then count observations\n",
    "grouped_counts = df_cleaned.groupby(['Date', 'Year', 'Venue']).size()\n",
    "\n",
    "# Define a function to check if counts meet the specified criteria\n",
    "def check_count(year, count):\n",
    "    if year <= 2018:\n",
    "        return count == 8 or count == 10\n",
    "    else:\n",
    "        return 4 <= count <= 16\n",
    "\n",
    "# Apply the function to each row in the grouped data and create a new column 'Count'\n",
    "correct_counts_df = grouped_counts.reset_index()\n",
    "correct_counts_df['Count'] = correct_counts_df.apply(lambda row: row[0], axis=1)\n",
    "\n",
    "# Filter rows where counts do not meet the criteria\n",
    "incorrect_counts_df = correct_counts_df[~correct_counts_df.apply(lambda row: check_count(row['Year'], row['Count']), axis=1)]\n",
    "\n",
    "# Check if the DataFrame is empty, indicating all matches are in the correct range\n",
    "if incorrect_counts_df.empty:\n",
    "    print(\"All matches are in the correct range.\")\n",
    "else:\n",
    "    # Display Date, Year, Venue, and Count when correct_counts is False\n",
    "    print(incorrect_counts_df[['Date', 'Year', 'Venue', 'Count']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check correspondance between data official website (davis matches) and https://github.com/JeffSackmann/tennis_atp/tree/master repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davis_single_df (331, 10)\n"
     ]
    }
   ],
   "source": [
    "# keep only rows for single matches\n",
    "davis_single_df = df_paired[df_paired['P2T1'].isna() & df_paired['P2T2'].isna()]\n",
    "print(\"davis_single_df\", davis_single_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match</th>\n",
       "      <th>Year</th>\n",
       "      <th>P1T1</th>\n",
       "      <th>P2T1</th>\n",
       "      <th>P1T2</th>\n",
       "      <th>P2T2</th>\n",
       "      <th>Date</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Court Pace Rating</th>\n",
       "      <th>Ball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>MATCH 1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Andy Murray</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Juan Martin del Potro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16 Sep - 18 Sep 2016</td>\n",
       "      <td>Emirates Arena, Glasgow, Great Britain</td>\n",
       "      <td>Medium Fast</td>\n",
       "      <td>Slazenger Wimbledon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>MATCH 2</td>\n",
       "      <td>2016</td>\n",
       "      <td>Ivo Karlovic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Juan Martin del Potro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25 Nov - 27 Nov 2016</td>\n",
       "      <td>Arena Zagreb, Zagreb, Croatia</td>\n",
       "      <td>Medium Slow</td>\n",
       "      <td>Wilson US Open Extra Duty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>MATCH 4</td>\n",
       "      <td>2016</td>\n",
       "      <td>Marin Cilic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Juan Martin del Potro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25 Nov - 27 Nov 2016</td>\n",
       "      <td>Arena Zagreb, Zagreb, Croatia</td>\n",
       "      <td>Medium Slow</td>\n",
       "      <td>Wilson US Open Extra Duty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Match  Year          P1T1 P2T1                   P1T2 P2T2  \\\n",
       "195  MATCH 1  2016   Andy Murray  NaN  Juan Martin del Potro  NaN   \n",
       "206  MATCH 2  2016  Ivo Karlovic  NaN  Juan Martin del Potro  NaN   \n",
       "208  MATCH 4  2016   Marin Cilic  NaN  Juan Martin del Potro  NaN   \n",
       "\n",
       "                      Date                                    Venue  \\\n",
       "195   16 Sep - 18 Sep 2016   Emirates Arena, Glasgow, Great Britain   \n",
       "206   25 Nov - 27 Nov 2016            Arena Zagreb, Zagreb, Croatia   \n",
       "208   25 Nov - 27 Nov 2016            Arena Zagreb, Zagreb, Croatia   \n",
       "\n",
       "    Court Pace Rating                        Ball  \n",
       "195       Medium Fast         Slazenger Wimbledon  \n",
       "206       Medium Slow   Wilson US Open Extra Duty  \n",
       "208       Medium Slow   Wilson US Open Extra Duty  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davis_single_df.loc[davis_single_df['P1T2'] == 'Juan Martin del Potro',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = f\"C:/Users/{user}/Documents/GitHub/davis-cup/data/single matches/\"\n",
    "\n",
    "# Initialize DataFrame to store all ATP matches where Davis Cup players took part\n",
    "combined_matches_df = pd.DataFrame()\n",
    "\n",
    "for year in range(2014, 2024):\n",
    "    # Filter Davis Cup data for the current year\n",
    "    davis_single_year_df = df_paired[df_paired['Year'] == year]\n",
    "\n",
    "    # Create a set of tuples representing pairs of players for the current year\n",
    "    davis_pairs = set(zip(davis_single_year_df['P1T1'], davis_single_year_df['P1T2']))\n",
    "\n",
    "    # Load ATP matches data for the current year\n",
    "    atp_matches_path = f\"{folder_path}atp_matches_{year}.csv\"\n",
    "    atp_matches_df = pd.read_csv(atp_matches_path)\n",
    "\n",
    "    # Filter ATP matches data to match Davis Cup pairs\n",
    "    matched_atp_matches_df = atp_matches_df[\n",
    "        atp_matches_df.apply(lambda row: (row['winner_name'], row['loser_name']) in davis_pairs or\n",
    "                                           (row['loser_name'], row['winner_name']) in davis_pairs, axis=1)\n",
    "    ]\n",
    "\n",
    "    # Append the filtered data to the combined DataFrame\n",
    "    combined_matches_df = combined_matches_df.append(matched_atp_matches_df)\n",
    "\n",
    "# # Extract the year information before the first hyphen in 'tourney_id'\n",
    "combined_matches_df['year'] = combined_matches_df['tourney_id'].str.split('-').str[0]\n",
    "\n",
    "# Convert 'year' column to integer\n",
    "combined_matches_df['year'] = combined_matches_df['year'].astype(int)\n",
    "\n",
    "# Save the combined data to a single Excel file\n",
    "final_output_path = f\"C:/Users/{user}/Documents/GitHub/davis-cup/data/single matches/filtered_atp_matches.xlsx\"\n",
    "combined_matches_df.to_excel(final_output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations with tourney_level 'D': 331\n",
      "Number of observations without tourney_level 'D': 117\n"
     ]
    }
   ],
   "source": [
    "# Count the number of observations where tourney_level is \"D\" - Davis Cup\n",
    "count_tourney_level_D = combined_matches_df[combined_matches_df['tourney_level'] == 'D'].shape[0]\n",
    "\n",
    "# Count the number of observations where tourney_level is not \"D\"\n",
    "count_not_tourney_level_D = combined_matches_df[combined_matches_df['tourney_level'] != 'D'].shape[0]\n",
    "\n",
    "print(\"Number of observations with tourney_level 'D':\", count_tourney_level_D)\n",
    "print(\"Number of observations without tourney_level 'D':\", count_not_tourney_level_D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "331 corresponds in both datasets combined_matches_df and davis_single_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DataFrame with observations where tourney_level is \"D\"\n",
    "davis_cup_matches_df = combined_matches_df[combined_matches_df['tourney_level'] == 'D']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2014, 1, 'Andreas Seppi', 'Carlos Berlocq'], [2014, 2, 'Fabio Fognini', 'Juan Monaco'], [2014, 4, 'Carlos Berlocq', 'Fabio Fognini'], [2014, 1, 'Radek Stepanek', 'Robin Haase'], [2014, 2, 'Igor Sijsling', 'Tomas Berdych']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating a list with year, match_num, winner_name, loser_name, where names are alphabetically ordered\n",
    "matches_list = davis_cup_matches_df.apply(\n",
    "    lambda row: [row['year'],row['match_num'], *sorted([row['winner_name'], row['loser_name']])], \n",
    "    axis=1\n",
    ").tolist()\n",
    "\n",
    "# Optionally, print the first few elements in the list to verify\n",
    "print(matches_list[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2014, 1, 'Radek Stepanek', 'Robin Haase'], [2014, 2, 'Igor Sijsling', 'Tomas Berdych'], [2014, 4, 'Thiemo De Bakker', 'Tomas Berdych'], [2014, 5, 'Igor Sijsling', 'Lukas Rosol'], [2014, 1, 'Kei Nishikori', 'Peter Polansky']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Assuming davis_single_df is your DataFrame\n",
    "\n",
    "# Convert 'Match' column to string type first, then clean it to keep only the number after \"MATCH\"\n",
    "davis_single_df['Match'] = davis_single_df['Match'].astype(str).str.replace('MATCH ', '').astype(int)\n",
    "\n",
    "# Creating a list with Year, cleaned Match, P1T1, P1T2, where player names are alphabetically ordered\n",
    "davis_single_list = davis_single_df.apply(\n",
    "    lambda row: [row['Year'], row['Match'], *sorted([row['P1T1'], row['P1T2']])],\n",
    "    axis=1\n",
    ").tolist()\n",
    "\n",
    "# Optionally, print the first few elements in the list to verify\n",
    "print(davis_single_list[:5])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-matching elements in standardized_matches_list: {(2014, 5, 'Daniel Brands', 'Roberto Bautista Agut')}\n",
      "Non-matching elements in standardized_davis_single_list: {(2014, 4, 'Daniel Brands', 'Roberto Bautista Agut')}\n",
      "Number of unmatched elements in standardized_matches_list: 1\n",
      "Number of unmatched elements in standardized_davis_single_list: 1\n"
     ]
    }
   ],
   "source": [
    "# Standardizing formats in matches_list and davis_single_list\n",
    "# Assuming year and match number are integers, and player names are strings\n",
    "\n",
    "standardized_matches_list = [\n",
    "    [int(year), int(match_num), str(winner_name), str(loser_name)]\n",
    "    for year, match_num, winner_name, loser_name in matches_list\n",
    "]\n",
    "\n",
    "standardized_davis_single_list = [\n",
    "    [int(year),int(match_num), str(player1), str(player2)]\n",
    "    for year, match_num, player1, player2 in davis_single_list\n",
    "]\n",
    "\n",
    "# Convert to sets of tuples for comparison\n",
    "standardized_matches_set = set(tuple(item) for item in standardized_matches_list)\n",
    "standardized_davis_single_set = set(tuple(item) for item in standardized_davis_single_list)\n",
    "\n",
    "# Find non-matching elements in both sets\n",
    "non_matching_in_standardized_matches = standardized_matches_set - standardized_davis_single_set\n",
    "non_matching_in_standardized_davis_single = standardized_davis_single_set - standardized_matches_set\n",
    "\n",
    "print(\"Non-matching elements in standardized_matches_list:\", non_matching_in_standardized_matches)\n",
    "print(\"Non-matching elements in standardized_davis_single_list:\", non_matching_in_standardized_davis_single)\n",
    "\n",
    "# Count the number of non-matching tuples in standardized_matches_list\n",
    "num_unmatched_in_standardized_matches = len(non_matching_in_standardized_matches)\n",
    "\n",
    "# Count the number of non-matching tuples in standardized_davis_single_list\n",
    "num_unmatched_in_standardized_davis_single = len(non_matching_in_standardized_davis_single)\n",
    "\n",
    "print(\"Number of unmatched elements in standardized_matches_list:\", num_unmatched_in_standardized_matches)\n",
    "print(\"Number of unmatched elements in standardized_davis_single_list:\", num_unmatched_in_standardized_davis_single)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final dataset single matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO create a unique dataset with davis cup and atp matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "info in combined_davis but not in filtered_atp_matches: venue, court pace rating, ball, match_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2014, 'Andreas Seppi', 'Carlos Berlocq'], [2014, 'Fabio Fognini', 'Juan Monaco'], [2014, 'Carlos Berlocq', 'Fabio Fognini'], [2014, 'Radek Stepanek', 'Robin Haase'], [2014, 'Igor Sijsling', 'Tomas Berdych']]\n"
     ]
    }
   ],
   "source": [
    "single_davis_list = davis_cup_matches_df.apply(\n",
    "    lambda row: [row['year'], *sorted([row['winner_name'], row['loser_name']])], \n",
    "    axis=1\n",
    ").tolist()\n",
    "\n",
    "# Optionally, print the first few elements in the list to verify\n",
    "print(single_davis_list[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert single_davis_list to a DataFrame for easier comparison\n",
    "columns = ['year', 'name1', 'name2']\n",
    "single_davis_df = pd.DataFrame(single_davis_list, columns=columns)\n",
    "\n",
    "# Explode single_davis_df into all possible pairs of name1 and name2 to match both conditions\n",
    "single_davis_df['winner_name'] = single_davis_df.apply(lambda x: x['name1'], axis=1)\n",
    "single_davis_df['loser_name'] = single_davis_df.apply(lambda x: x['name2'], axis=1)\n",
    "expanded_single_davis_df = pd.concat([\n",
    "    single_davis_df[['year', 'winner_name', 'loser_name']],\n",
    "    single_davis_df.rename(columns={'winner_name': 'loser_name', 'loser_name': 'winner_name'})[['year', 'winner_name', 'loser_name']]\n",
    "])\n",
    "\n",
    "# Drop duplicates since the second concat may create identical rows due to name swapping\n",
    "expanded_single_davis_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Now, filter combined_matches_df using a merge operation, which naturally implements the AND condition for year and names\n",
    "single_matches = pd.merge(combined_matches_df, expanded_single_davis_df, on=['year', 'winner_name', 'loser_name'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "understand if I do not have already all the data in combined_matches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448, 50)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_matches_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to keep rows where P1T1, P2T1, P1T2, P2T2 are all non-NA\n",
    "davis_double_df = df_paired.dropna(subset=['P1T1', 'P2T1', 'P1T2', 'P2T2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davis_double_df (92, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"davis_double_df\", davis_double_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "folder_path = f\"C:/Users/{user}/Documents/GitHub/davis-cup/data/double matches/\"\n",
    "\n",
    "# Initialize DataFrame to store all ATP matches where Davis Cup players took part in doubles\n",
    "combined_matches_df = pd.DataFrame()\n",
    "\n",
    "for year in range(2014, 2021):  # Adjusted the range to end at 2020\n",
    "    # Filter Davis Cup data for the current year\n",
    "    davis_double_year_df = df_paired[df_paired['Year'] == year]\n",
    "\n",
    "    # Assuming the columns for player names in doubles are similarly named or adjusted as necessary\n",
    "    team1 = set(zip(davis_double_year_df['P1T1'], davis_double_year_df['P2T1']))\n",
    "    team2 = set(zip(davis_double_year_df['P1T2'], davis_double_year_df['P2T2']))\n",
    "\n",
    "    # Load ATP doubles matches data for the current year\n",
    "    atp_matches_doubles_path = f\"{folder_path}atp_matches_doubles_{year}.csv\"\n",
    "    atp_matches_doubles_df = pd.read_csv(atp_matches_doubles_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "Index(['year', 'name1', 'name2', 'winner_name', 'loser_name'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check column names in combined_matches_df\n",
    "print(combined_matches_df.columns)\n",
    "\n",
    "# If you have already created single_davis_df, check its columns too\n",
    "print(single_davis_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported to C:/Users/aldi/Documents/GitHub/davis-cup/data/singles_paired.xlsx\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/Users/aldi/Documents/GitHub/davis-cup/data/single_matches.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-bcc271416678>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Export the DataFrame to an Excel file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0msingle_matches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"DataFrame exported to {file_path}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2289\u001b[0m             \u001b[0mfreeze_panes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfreeze_panes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2290\u001b[0m             \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2291\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2292\u001b[0m         )\n\u001b[0;32m   2293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\formats\\excel.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    833\u001b[0m             \u001b[1;31m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             writer = ExcelWriter(  # type: ignore[abstract]\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m             )\n\u001b[0;32m    837\u001b[0m             \u001b[0mneed_save\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[0mif_sheet_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mif_sheet_exists\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m             \u001b[0mengine_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         )\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    924\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m             self.handles = get_handle(\n\u001b[1;32m--> 926\u001b[1;33m                 \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m             )\n\u001b[0;32m    928\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msheets\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:/Users/aldi/Documents/GitHub/davis-cup/data/single_matches.xlsx'"
     ]
    }
   ],
   "source": [
    "file_path = f\"C:/Users/{user}/Documents/GitHub/davis-cup/data/singles_paired.xlsx\"\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "df_paired.to_excel(file_path, index=False)\n",
    "\n",
    "print(f\"DataFrame exported to {file_path}\")\n",
    "\n",
    "\n",
    "file_path = f\"C:/Users/{user}/Documents/GitHub/davis-cup/data/single_matches.xlsx\"\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "single_matches.to_excel(file_path, index=False)\n",
    "\n",
    "print(f\"DataFrame exported to {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
