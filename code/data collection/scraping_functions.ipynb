{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import sys\n",
    "from getpass import getuser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lists functions to extract matches and players ' information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current user's name\n",
    "user = getuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_matches_df(url):\n",
    "    try:\n",
    "        # Initialize Selenium\n",
    "        print(\"Initializing Selenium...\")\n",
    "        chrome_service = ChromeService(f\"C:/Users/{user}/Downloads/chromedriver.exe\")\n",
    "        chrome_service.start()\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "        # Navigate to the webpage\n",
    "        print(\"Navigating to the webpage...\")\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the page to be loaded\n",
    "        print(\"Waiting for the page to load...\")\n",
    "        loaded = False\n",
    "        while not loaded:\n",
    "            try:\n",
    "                main_element = driver.find_element(By.CLASS_NAME, \"main\")\n",
    "                loaded = True\n",
    "            except:\n",
    "                time.sleep(1)\n",
    "        # ---------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Find the div element with class \"main\"\n",
    "        main_element = driver.find_element(By.CLASS_NAME, \"main\")\n",
    "\n",
    "        # Include the component_title_text in the stage variable\n",
    "        component_title_element = main_element.find_element(By.CLASS_NAME, \"component-title\")\n",
    "        stage = component_title_element.text.strip()\n",
    "\n",
    "        # ---------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Now, let's find the div element with class \"tie\" within the main element\n",
    "        tie_element = main_element.find_element(By.CLASS_NAME, \"details\")\n",
    "\n",
    "        # Find all sub div elements within the \"tie\" element\n",
    "        sub_div_elements = tie_element.find_elements(By.TAG_NAME, \"div\")\n",
    "\n",
    "        # Initialize variables to store data\n",
    "        column_data = {}\n",
    "\n",
    "        for sub_div_element in sub_div_elements:\n",
    "            sub_div_text = sub_div_element.text.strip()\n",
    "            if \":\" in sub_div_text:\n",
    "                column_name, column_value = sub_div_text.split(\":\", 1)\n",
    "                column_data[column_name] = [column_value]\n",
    "\n",
    "        # Create a DataFrame from the collected data\n",
    "        df = pd.DataFrame(column_data)\n",
    "\n",
    "        # Add the \"stage\" column with the component_title_text\n",
    "        df[\"stage\"] = stage\n",
    "\n",
    "        # ---------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Find the div element with class \"rubber-header\"\n",
    "        rubber_header_elements = main_element.find_elements(By.CLASS_NAME, \"rubber-header\")\n",
    "        match_num = []\n",
    "        match_status = []\n",
    "\n",
    "        for rubber_header_element in rubber_header_elements:\n",
    "\n",
    "            # Extract \"match\" and \"match status\" from the span elements\n",
    "            spans = rubber_header_element.find_elements(By.TAG_NAME, \"span\")\n",
    "\n",
    "            if len(spans) >= 2:\n",
    "                match_num.append(spans[0].text.strip())\n",
    "                match_status.append(spans[1].text.strip())\n",
    "            #       match = span_element.text.strip()\n",
    "\n",
    "        # ---------------------------------------------------------------------------------------------\n",
    "        # Now, let's find the div element with class \"rubber-body\" within the main element\n",
    "        rubber_body_elements = main_element.find_elements(By.CLASS_NAME, \"rubber-body\")\n",
    "        tables_data = []\n",
    "\n",
    "        match_idx = -1\n",
    "        for rubber_body_element in rubber_body_elements:\n",
    "            match_idx += 1\n",
    "\n",
    "            # Find all tables with class \"dc\" within the rubber-body\n",
    "            table_elements = rubber_body_element.find_elements(By.CLASS_NAME, \"dc\")\n",
    "\n",
    "            for table_element in table_elements:\n",
    "                # Initialize data for each table\n",
    "                table_data = {\n",
    "                    \"player\": [],\n",
    "                    \"set1\": [],\n",
    "                    \"set2\": [],\n",
    "                    \"set3\": [],\n",
    "                    \"set4\": [],\n",
    "                    \"set5\": [],\n",
    "                    \"tb1\": [],\n",
    "                    \"tb2\": [],\n",
    "                    \"tb3\": [],\n",
    "                    \"tb4\": [],\n",
    "                    \"tb5\": []\n",
    "                }\n",
    "\n",
    "                # Find the table body\n",
    "                tbody_element = table_element.find_element(By.TAG_NAME, \"tbody\")\n",
    "\n",
    "                # Find all rows (tr elements) within the tbody\n",
    "                rows = tbody_element.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "                for row in rows:\n",
    "                    # Find all td elements within the row\n",
    "                    td_elements = row.find_elements(By.TAG_NAME, \"td\")\n",
    "\n",
    "                    # Extract and store the information starting from td_elements[1]\n",
    "                    player = td_elements[1].text.strip()\n",
    "\n",
    "                    # Skip set and tie-break infos if match hasn't been played\n",
    "                    if match_status[match_idx] in [\"NOT PLAYED\", \"WALKOVER\"]:\n",
    "                        print(f\"Skipping match {match_idx+1}\")\n",
    "                        continue\n",
    "\n",
    "                    # Extract results from td class \"results\"\n",
    "                    results = td_elements[2]\n",
    "                    set_scores = results.find_elements(By.TAG_NAME, \"span\")\n",
    "\n",
    "                    set_results = [None, None, None, None, None]\n",
    "                    tie_breaks = [None, None, None, None, None]\n",
    "\n",
    "                    for set_score_idx in range(len(set_scores)):\n",
    "                        set_score= set_scores[set_score_idx]\n",
    "                        scores = set_score.text.strip().split()  # Split by whitespace to extract numbers\n",
    "                        set_results[set_score_idx]= scores[0]\n",
    "                        if len(scores)>1:\n",
    "                            tie_breaks[set_score_idx] = scores[1]\n",
    "                    \n",
    "                    \n",
    "                    # Assign the extracted values to the dictionary\n",
    "                    table_data[\"player\"].append(player)\n",
    "                    for i in range(5):\n",
    "                        table_data[f\"set{i+1}\"].append(set_results[i])\n",
    "                        table_data[f\"tb{i+1}\"].append(tie_breaks[i])\n",
    "                    # Append the table data to the list\n",
    "                    tables_data.append(table_data)\n",
    "\n",
    "        # Close the Selenium WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "        # Create a DataFrame from the collected data\n",
    "        tables_df = pd.DataFrame(tables_data)\n",
    "\n",
    "        # Combine the information from both DataFrames\n",
    "        matches_df = pd.concat([df] * len(tables_df), ignore_index=True)\n",
    "        matches_df = pd.concat([matches_df, tables_df], axis=1)\n",
    "\n",
    "        # Add match and match status columns\n",
    "        matches_df[\"match status\"] = \"\"\n",
    "        matches_df[\"match\"] = \"\"\n",
    "        for i in range(len(match_status)):\n",
    "            matches_df.loc[i * 2:(i * 2) + 1, \"match status\"] = match_status[i]\n",
    "            matches_df.loc[i * 2:(i * 2) + 1, \"match\"] = match_num[i]\n",
    "        print(\"matches df downloaded\")\n",
    "        return matches_df\n",
    "    except Exception as e:\n",
    "        exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "        print(f\"[ERROR] Exception occurred: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_players_df(url):\n",
    "    try:\n",
    "        # Initialize Selenium\n",
    "        chrome_service = ChromeService(f\"C:/Users/{user}/Downloads/chromedriver.exe\")\n",
    "        chrome_service.start()\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "        # Navigate to the webpage\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the page to load\n",
    "        loaded = False\n",
    "        while not loaded:\n",
    "            try:\n",
    "                main_element = driver.find_element(By.CLASS_NAME, \"main\")\n",
    "                loaded = True\n",
    "            except:\n",
    "                time.sleep(1)\n",
    "\n",
    "        # Wait for the page to load\n",
    "        driver.implicitly_wait(10)  # You can adjust the waiting time as needed\n",
    "\n",
    "        # Find all div elements with class \"team-nominations-col\"\n",
    "        team_nominations_col_elements = driver.find_elements(By.CLASS_NAME, \"team-nominations-col\")\n",
    "\n",
    "        # Initialize a list to store the paired data\n",
    "        paired_data = []\n",
    "\n",
    "        # Initialize a list to store the column names\n",
    "        column_names = set()\n",
    "\n",
    "        # Loop through each \"team-nominations-col\" element\n",
    "        for team_nominations_col_element in team_nominations_col_elements:\n",
    "            # Extract the team name\n",
    "            team_name_element = team_nominations_col_element.find_element(By.CLASS_NAME, \"team-name\")\n",
    "            team_name = team_name_element.text.strip()\n",
    "\n",
    "            # Find \"players-info\" elements and extract text from \"ng-binding\" elements\n",
    "            players_info_elements = team_nominations_col_element.find_elements(By.CLASS_NAME, \"players-info\")\n",
    "\n",
    "            for players_info_element in players_info_elements:\n",
    "                ng_binding_elements = players_info_element.find_elements(By.CLASS_NAME, \"ng-binding\")\n",
    "\n",
    "                # Create a dictionary for the row\n",
    "                row_data = {\"team_name\": team_name}\n",
    "\n",
    "                for i, ng_binding_element in enumerate(ng_binding_elements, start=1):\n",
    "                    row_data[f\"Info {i}\"] = ng_binding_element.text.strip()\n",
    "                    column_names.add(f\"Info {i}\")\n",
    "\n",
    "                paired_data.append(row_data)\n",
    "\n",
    "        # Create a Pandas DataFrame from the paired data\n",
    "        players_df = pd.DataFrame(paired_data)\n",
    "\n",
    "        # Reorder columns to match the column names\n",
    "        players_df = players_df[[\"team_name\"] + sorted(column_names)]\n",
    "\n",
    "        # Now you have a DataFrame with team names and player information in separate columns\n",
    "        print(\"players df downloaded\")\n",
    "        return players_df\n",
    "\n",
    "    except Exception as e:\n",
    "        exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "        print(f\"[ERROR] Exception occurred: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and clean dataframe function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(links):\n",
    "    # Initialize Selenium\n",
    "    chrome_service = ChromeService(f\"C:/Users/{user}/Downloads/chromedriver.exe\")\n",
    "    chrome_service.start()\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        # Create empty lists to store the results\n",
    "        match_results = []\n",
    "        player_results = []\n",
    "\n",
    "        for link in links:\n",
    "            try:\n",
    "                print(f\"Processing match: {link}\")  # Print the link being analyzed\n",
    "\n",
    "                # Apply the functions to extract match and player data\n",
    "                matches_df = extract_matches_df(link)\n",
    "                players_df = extract_players_df(link)\n",
    "\n",
    "                if matches_df is not None:\n",
    "                    match_results.append(matches_df)\n",
    "                if players_df is not None:\n",
    "                    player_results.append(players_df)\n",
    "\n",
    "            except Exception as inner_e:\n",
    "                # Handle any errors that occur during the processing of each link\n",
    "                print(f\"[ERROR] Failed to process link {link}: {str(inner_e)}\")\n",
    "                continue  # Skip to the next link if there's an error\n",
    "\n",
    "        # Create DataFrames from the lists\n",
    "        if match_results:\n",
    "            matches_df = pd.concat(match_results, ignore_index=True)\n",
    "        else:\n",
    "            matches_df = pd.DataFrame()  # Return an empty DataFrame if no matches\n",
    "\n",
    "        if player_results:\n",
    "            players_df = pd.concat(player_results, ignore_index=True)\n",
    "        else:\n",
    "            players_df = pd.DataFrame()  # Return an empty DataFrame if no players\n",
    "\n",
    "        # Check the number of rows in the DataFrames\n",
    "        print(\"Total number of rows in matches_df:\", len(matches_df))\n",
    "        print(\"Total number of rows in players_df:\", len(players_df))\n",
    "\n",
    "        return matches_df, players_df\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any errors that occur in the main processing\n",
    "        exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "        print(f\"[ERROR] Line {exc_traceback.tb_lineno}: {str(e)}\")\n",
    "        return None, None  # Return None if there was an error\n",
    "\n",
    "    finally:\n",
    "        # Ensure the WebDriver is always closed, even if an error occurs\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean players and matches dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean players dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_players_df(players_df):\n",
    "    # Remove rows where Info 1 is equal to \"captain\"\n",
    "    players_df = players_df[players_df[\"Info 1\"] != \"Captain\"]\n",
    "    \n",
    "    # Rename the columns\n",
    "    players_df = players_df.rename(columns={\"Info 1\": \"player\", \"Info 2\": \"dob\", \"Info 3\": \"single_ranking\", \"Info 4\": \"doubles_ranking\"})\n",
    "    \n",
    "    # Remove text before \":\" in the specified columns\n",
    "    players_df[\"dob\"] = players_df[\"dob\"].str.split(\":\", expand=True)[1].str.strip()\n",
    "    players_df[\"single_ranking\"] = players_df[\"single_ranking\"].str.split(\":\", expand=True)[1].str.strip()\n",
    "    players_df[\"doubles_ranking\"] = players_df[\"doubles_ranking\"].str.split(\":\", expand=True)[1].str.strip()\n",
    "    \n",
    "    # Keep the first letter in each word in uppercase for the \"player\" column in players_df\n",
    "    players_df['player'] = players_df['player'].str.title()\n",
    "    \n",
    "    return players_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean matches dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_matches_df(matches_df):\n",
    "    # Convert \"player\" and set columns to string\n",
    "    columns_to_convert = [\"player\", \"set1\", \"set2\", \"set3\", \"set4\", \"set5\",\n",
    "                          \"tb1\", \"tb2\", \"tb3\", \"tb4\", \"tb5\"]\n",
    "    matches_df[columns_to_convert] = matches_df[columns_to_convert].astype(str)\n",
    "\n",
    "    # Define a function to apply regular expression replacements\n",
    "    def apply_regex_replacements(df, columns):\n",
    "        for col in columns:\n",
    "            df[col] = df[col].str.replace(r'[\\[\\]\\']+| and ', '', regex=True)\n",
    "\n",
    "    # Apply the function to the specified columns\n",
    "    columns_to_clean = [\"player\", \"set1\", \"set2\", \"set3\", \"set4\", \"set5\",\n",
    "                          \"tb1\", \"tb2\", \"tb3\", \"tb4\", \"tb5\"]\n",
    "    apply_regex_replacements(matches_df, columns_to_clean)\n",
    "\n",
    "    # Apply the str.extract method with the specified regular expression\n",
    "    split_players = matches_df['player'].str.extract(r'^(.*?)\\\\n(.*)$')\n",
    "    \n",
    "    # Create 'player1' and 'player2' columns\n",
    "    matches_df['player1'] = split_players[0].fillna(matches_df['player'])\n",
    "    matches_df['player2'] = split_players[1].fillna('')\n",
    "    \n",
    "    # Drop the original 'player' column\n",
    "    matches_df.drop('player', axis=1, inplace=True)\n",
    "    \n",
    "    # Keep the first letter in each word in uppercase for the \"player1\" and \"player2\" columns\n",
    "    matches_df[\"player1\"] = matches_df[\"player1\"].str.title()\n",
    "    matches_df[\"player2\"] = matches_df[\"player2\"].str.title()\n",
    "    \n",
    "    # Define a function to convert specific columns from string to numeric\n",
    "    def convert_columns_to_numeric(df, columns):\n",
    "        for col in columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Specify the columns to convert\n",
    "    columns_to_convert = [\"set1\", \"set2\", \"set3\", \"set4\", \"set5\",\n",
    "                          \"tb1\", \"tb2\", \"tb3\", \"tb4\", \"tb5\"]\n",
    "\n",
    "    # Apply the function to convert the specified columns\n",
    "    convert_columns_to_numeric(matches_df, columns_to_convert)\n",
    "    \n",
    "    return matches_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge players and matches dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data_frames(df1, df2):\n",
    "    merged_df = df1.merge(df2, left_on='player1', right_on='player', how='left')\n",
    "    merged_df = merged_df.drop_duplicates()\n",
    "\n",
    "    # Second merge based on 'player2'\n",
    "    final_merged = merged_df.merge(df2, left_on='player2', right_on='player', how='left')\n",
    "    final_merged = final_merged.drop_duplicates()\n",
    "\n",
    "    # Dropping specified columns\n",
    "    columns_to_drop = ['player_x', 'player_y', 'team_name_y']\n",
    "    final_merged = final_merged.drop(columns_to_drop, axis=1)\n",
    "\n",
    "    # Renaming columns based on suffixes\n",
    "    final_merged = final_merged.rename(columns=lambda x: x.replace('_x', '_player1').replace('_y', '_player2'))\n",
    "\n",
    "    # Renaming 'Team Name_Player1' to 'team_name'\n",
    "    final_merged = final_merged.rename(columns={'team_name_player1': 'team_name'})\n",
    "\n",
    "    return final_merged\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
